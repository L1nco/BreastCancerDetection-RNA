[
    {
        "test_evaluation": {
            "test_loss": 0.06179587543010712,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.9962331652641296,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9834254143646409,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9902642559109874,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951690821256038,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9832935560859188,
                    "support": 212.0
                },
                "accuracy": 0.9876977152899824,
                "macro avg": {
                    "precision": 0.9892972482451223,
                    "recall": 0.984448496379684,
                    "f1-score": 0.9867789059984531,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9878009109645076,
                    "recall": 0.9876977152899824,
                    "f1-score": 0.9876670883135981,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9834254143646409,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9902642559109874,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951690821256038,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9832935560859188,
                    "support": 212.0
                },
                "accuracy": 0.9876977152899824,
                "macro avg": {
                    "precision": 0.9892972482451223,
                    "recall": 0.984448496379684,
                    "f1-score": 0.9867789059984531,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9878009109645076,
                    "recall": 0.9876977152899824,
                    "f1-score": 0.9876670883135981,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    356,
                    1
                ],
                [
                    6,
                    206
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.09483101218938828,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.9911764860153198,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9861495844875346,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9916434540389972,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951923076923077,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9857142857142858,
                    "support": 212.0
                },
                "accuracy": 0.9894551845342706,
                "macro avg": {
                    "precision": 0.9906709460899212,
                    "recall": 0.9868069869457217,
                    "f1-score": 0.9886788698766416,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9895187537659387,
                    "recall": 0.9894551845342706,
                    "f1-score": 0.9894343438723209,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9861495844875346,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9916434540389972,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951923076923077,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9857142857142858,
                    "support": 212.0
                },
                "accuracy": 0.9894551845342706,
                "macro avg": {
                    "precision": 0.9906709460899212,
                    "recall": 0.9868069869457217,
                    "f1-score": 0.9886788698766416,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9895187537659387,
                    "recall": 0.9894551845342706,
                    "f1-score": 0.9894343438723209,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    356,
                    1
                ],
                [
                    5,
                    207
                ]
            ]
        }
    }
]