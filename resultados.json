[
    {
        "test_evaluation": {
            "test_loss": 0.06179587543010712,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.9962331652641296,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9834254143646409,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9902642559109874,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951690821256038,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9832935560859188,
                    "support": 212.0
                },
                "accuracy": 0.9876977152899824,
                "macro avg": {
                    "precision": 0.9892972482451223,
                    "recall": 0.984448496379684,
                    "f1-score": 0.9867789059984531,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9878009109645076,
                    "recall": 0.9876977152899824,
                    "f1-score": 0.9876670883135981,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9834254143646409,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9902642559109874,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951690821256038,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9832935560859188,
                    "support": 212.0
                },
                "accuracy": 0.9876977152899824,
                "macro avg": {
                    "precision": 0.9892972482451223,
                    "recall": 0.984448496379684,
                    "f1-score": 0.9867789059984531,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9878009109645076,
                    "recall": 0.9876977152899824,
                    "f1-score": 0.9876670883135981,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    356,
                    1
                ],
                [
                    6,
                    206
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.09483101218938828,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.9911764860153198,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9861495844875346,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9916434540389972,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951923076923077,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9857142857142858,
                    "support": 212.0
                },
                "accuracy": 0.9894551845342706,
                "macro avg": {
                    "precision": 0.9906709460899212,
                    "recall": 0.9868069869457217,
                    "f1-score": 0.9886788698766416,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9895187537659387,
                    "recall": 0.9894551845342706,
                    "f1-score": 0.9894343438723209,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9861495844875346,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9916434540389972,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951923076923077,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9857142857142858,
                    "support": 212.0
                },
                "accuracy": 0.9894551845342706,
                "macro avg": {
                    "precision": 0.9906709460899212,
                    "recall": 0.9868069869457217,
                    "f1-score": 0.9886788698766416,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9895187537659387,
                    "recall": 0.9894551845342706,
                    "f1-score": 0.9894343438723209,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    356,
                    1
                ],
                [
                    5,
                    207
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.07032114267349243,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.9954143762588501,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9834254143646409,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9902642559109874,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951690821256038,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9832935560859188,
                    "support": 212.0
                },
                "accuracy": 0.9876977152899824,
                "macro avg": {
                    "precision": 0.9892972482451223,
                    "recall": 0.984448496379684,
                    "f1-score": 0.9867789059984531,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9878009109645076,
                    "recall": 0.9876977152899824,
                    "f1-score": 0.9876670883135981,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9834254143646409,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9902642559109874,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951690821256038,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9832935560859188,
                    "support": 212.0
                },
                "accuracy": 0.9876977152899824,
                "macro avg": {
                    "precision": 0.9892972482451223,
                    "recall": 0.984448496379684,
                    "f1-score": 0.9867789059984531,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9878009109645076,
                    "recall": 0.9876977152899824,
                    "f1-score": 0.9876670883135981,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    356,
                    1
                ],
                [
                    6,
                    206
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.09604433923959732,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.9911764860153198,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9861878453038674,
                    "recall": 1.0,
                    "f1-score": 0.9930458970792768,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 1.0,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9880668257756563,
                    "support": 212.0
                },
                "accuracy": 0.9912126537785588,
                "macro avg": {
                    "precision": 0.9930939226519337,
                    "recall": 0.9882075471698113,
                    "f1-score": 0.9905563614274666,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9913340259639379,
                    "recall": 0.9912126537785588,
                    "f1-score": 0.9911907773668558,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9861878453038674,
                    "recall": 1.0,
                    "f1-score": 0.9930458970792768,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 1.0,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9880668257756563,
                    "support": 212.0
                },
                "accuracy": 0.9912126537785588,
                "macro avg": {
                    "precision": 0.9930939226519337,
                    "recall": 0.9882075471698113,
                    "f1-score": 0.9905563614274666,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9913340259639379,
                    "recall": 0.9912126537785588,
                    "f1-score": 0.9911907773668558,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    357,
                    0
                ],
                [
                    5,
                    207
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.052264586091041565,
            "test_accuracy": 0.9859648942947388,
            "test_auc": 0.997899055480957,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9860335195530726,
                    "recall": 0.988795518207283,
                    "f1-score": 0.9874125874125874,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.981042654028436,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9787234042553191,
                    "support": 212.0
                },
                "accuracy": 0.984182776801406,
                "macro avg": {
                    "precision": 0.9835380867907544,
                    "recall": 0.9826053062734528,
                    "f1-score": 0.9830679958339532,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.984174005508744,
                    "recall": 0.984182776801406,
                    "f1-score": 0.9841751413153276,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9860335195530726,
                    "recall": 0.988795518207283,
                    "f1-score": 0.9874125874125874,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.981042654028436,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9787234042553191,
                    "support": 212.0
                },
                "accuracy": 0.984182776801406,
                "macro avg": {
                    "precision": 0.9835380867907544,
                    "recall": 0.9826053062734528,
                    "f1-score": 0.9830679958339532,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.984174005508744,
                    "recall": 0.984182776801406,
                    "f1-score": 0.9841751413153276,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    353,
                    4
                ],
                [
                    5,
                    207
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.05667124316096306,
            "test_accuracy": 0.9766082167625427,
            "test_auc": 0.9963257312774658,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9778393351800554,
                    "recall": 0.988795518207283,
                    "f1-score": 0.9832869080779945,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9807692307692307,
                    "recall": 0.9622641509433962,
                    "f1-score": 0.9714285714285714,
                    "support": 212.0
                },
                "accuracy": 0.9789103690685413,
                "macro avg": {
                    "precision": 0.979304282974643,
                    "recall": 0.9755298345753396,
                    "f1-score": 0.9773577397532829,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9789309658740891,
                    "recall": 0.9789103690685413,
                    "f1-score": 0.9788686877446418,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9778393351800554,
                    "recall": 0.988795518207283,
                    "f1-score": 0.9832869080779945,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9807692307692307,
                    "recall": 0.9622641509433962,
                    "f1-score": 0.9714285714285714,
                    "support": 212.0
                },
                "accuracy": 0.9789103690685413,
                "macro avg": {
                    "precision": 0.979304282974643,
                    "recall": 0.9755298345753396,
                    "f1-score": 0.9773577397532829,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9789309658740891,
                    "recall": 0.9789103690685413,
                    "f1-score": 0.9788686877446418,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    353,
                    4
                ],
                [
                    8,
                    204
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.1034836694598198,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.966176450252533,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9861878453038674,
                    "recall": 1.0,
                    "f1-score": 0.9930458970792768,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 1.0,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9880668257756563,
                    "support": 212.0
                },
                "accuracy": 0.9912126537785588,
                "macro avg": {
                    "precision": 0.9930939226519337,
                    "recall": 0.9882075471698113,
                    "f1-score": 0.9905563614274666,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9913340259639379,
                    "recall": 0.9912126537785588,
                    "f1-score": 0.9911907773668558,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9861878453038674,
                    "recall": 1.0,
                    "f1-score": 0.9930458970792768,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 1.0,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9880668257756563,
                    "support": 212.0
                },
                "accuracy": 0.9912126537785588,
                "macro avg": {
                    "precision": 0.9930939226519337,
                    "recall": 0.9882075471698113,
                    "f1-score": 0.9905563614274666,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9913340259639379,
                    "recall": 0.9912126537785588,
                    "f1-score": 0.9911907773668558,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    357,
                    0
                ],
                [
                    5,
                    207
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.1759365350008011,
            "test_accuracy": 0.9317739009857178,
            "test_auc": 0.9822539687156677,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9445983379501385,
                    "recall": 0.9551820728291317,
                    "f1-score": 0.9498607242339833,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9230769230769231,
                    "recall": 0.9056603773584906,
                    "f1-score": 0.9142857142857143,
                    "support": 212.0
                },
                "accuracy": 0.9367311072056239,
                "macro avg": {
                    "precision": 0.9338376305135307,
                    "recall": 0.9304212250938111,
                    "f1-score": 0.9320732192598488,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.936579814306691,
                    "recall": 0.9367311072056239,
                    "f1-score": 0.9366060632339253,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9445983379501385,
                    "recall": 0.9551820728291317,
                    "f1-score": 0.9498607242339833,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9230769230769231,
                    "recall": 0.9056603773584906,
                    "f1-score": 0.9142857142857143,
                    "support": 212.0
                },
                "accuracy": 0.9367311072056239,
                "macro avg": {
                    "precision": 0.9338376305135307,
                    "recall": 0.9304212250938111,
                    "f1-score": 0.9320732192598488,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.936579814306691,
                    "recall": 0.9367311072056239,
                    "f1-score": 0.9366060632339253,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    341,
                    16
                ],
                [
                    20,
                    192
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.057696521282196045,
            "test_accuracy": 0.9719298481941223,
            "test_auc": 0.9978718757629395,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9830985915492958,
                    "recall": 0.9775910364145658,
                    "f1-score": 0.9803370786516854,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9626168224299065,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9671361502347418,
                    "support": 212.0
                },
                "accuracy": 0.9753954305799648,
                "macro avg": {
                    "precision": 0.9728577069896012,
                    "recall": 0.9746445748110565,
                    "f1-score": 0.9737366144432136,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9754674227385567,
                    "recall": 0.9753954305799648,
                    "f1-score": 0.9754186308056537,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9830985915492958,
                    "recall": 0.9775910364145658,
                    "f1-score": 0.9803370786516854,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9626168224299065,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9671361502347418,
                    "support": 212.0
                },
                "accuracy": 0.9753954305799648,
                "macro avg": {
                    "precision": 0.9728577069896012,
                    "recall": 0.9746445748110565,
                    "f1-score": 0.9737366144432136,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9754674227385567,
                    "recall": 0.9753954305799648,
                    "f1-score": 0.9754186308056537,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    349,
                    8
                ],
                [
                    6,
                    206
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.08277299255132675,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.991911768913269,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9861495844875346,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9916434540389972,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951923076923077,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9857142857142858,
                    "support": 212.0
                },
                "accuracy": 0.9894551845342706,
                "macro avg": {
                    "precision": 0.9906709460899212,
                    "recall": 0.9868069869457217,
                    "f1-score": 0.9886788698766416,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9895187537659387,
                    "recall": 0.9894551845342706,
                    "f1-score": 0.9894343438723209,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9861495844875346,
                    "recall": 0.9971988795518207,
                    "f1-score": 0.9916434540389972,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9951923076923077,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9857142857142858,
                    "support": 212.0
                },
                "accuracy": 0.9894551845342706,
                "macro avg": {
                    "precision": 0.9906709460899212,
                    "recall": 0.9868069869457217,
                    "f1-score": 0.9886788698766416,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9895187537659387,
                    "recall": 0.9894551845342706,
                    "f1-score": 0.9894343438723209,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    356,
                    1
                ],
                [
                    5,
                    207
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.05066221207380295,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.9977954626083374,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9833333333333333,
                    "recall": 0.9915966386554622,
                    "f1-score": 0.9874476987447699,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9856459330143541,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9786223277909739,
                    "support": 212.0
                },
                "accuracy": 0.984182776801406,
                "macro avg": {
                    "precision": 0.9844896331738437,
                    "recall": 0.9816473759315048,
                    "f1-score": 0.9830350132678719,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9841949697698472,
                    "recall": 0.984182776801406,
                    "f1-score": 0.9841595113243748,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9833333333333333,
                    "recall": 0.9915966386554622,
                    "f1-score": 0.9874476987447699,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9856459330143541,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9786223277909739,
                    "support": 212.0
                },
                "accuracy": 0.984182776801406,
                "macro avg": {
                    "precision": 0.9844896331738437,
                    "recall": 0.9816473759315048,
                    "f1-score": 0.9830350132678719,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9841949697698472,
                    "recall": 0.984182776801406,
                    "f1-score": 0.9841595113243748,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    354,
                    3
                ],
                [
                    6,
                    206
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.06086239591240883,
            "test_accuracy": 0.9719298481941223,
            "test_auc": 0.9977627396583557,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9859154929577465,
                    "recall": 0.9803921568627451,
                    "f1-score": 0.9831460674157303,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9672897196261683,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.971830985915493,
                    "support": 212.0
                },
                "accuracy": 0.9789103690685413,
                "macro avg": {
                    "precision": 0.9766026062919574,
                    "recall": 0.9784036256011839,
                    "f1-score": 0.9774885266656117,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.978975837516104,
                    "recall": 0.9789103690685413,
                    "f1-score": 0.9789302549762746,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9859154929577465,
                    "recall": 0.9803921568627451,
                    "f1-score": 0.9831460674157303,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9672897196261683,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.971830985915493,
                    "support": 212.0
                },
                "accuracy": 0.9789103690685413,
                "macro avg": {
                    "precision": 0.9766026062919574,
                    "recall": 0.9784036256011839,
                    "f1-score": 0.9774885266656117,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.978975837516104,
                    "recall": 0.9789103690685413,
                    "f1-score": 0.9789302549762746,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    350,
                    7
                ],
                [
                    5,
                    207
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.060640543699264526,
            "test_accuracy": 0.9789473414421082,
            "test_auc": 0.9977080821990967,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9859550561797753,
                    "recall": 0.9831932773109243,
                    "f1-score": 0.9845722300140253,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.971830985915493,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9741176470588235,
                    "support": 212.0
                },
                "accuracy": 0.9806678383128296,
                "macro avg": {
                    "precision": 0.9788930210476341,
                    "recall": 0.9798041858252735,
                    "f1-score": 0.9793449385364243,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9806926609319232,
                    "recall": 0.9806678383128296,
                    "f1-score": 0.9806770251168323,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9859550561797753,
                    "recall": 0.9831932773109243,
                    "f1-score": 0.9845722300140253,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.971830985915493,
                    "recall": 0.9764150943396226,
                    "f1-score": 0.9741176470588235,
                    "support": 212.0
                },
                "accuracy": 0.9806678383128296,
                "macro avg": {
                    "precision": 0.9788930210476341,
                    "recall": 0.9798041858252735,
                    "f1-score": 0.9793449385364243,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9806926609319232,
                    "recall": 0.9806678383128296,
                    "f1-score": 0.9806770251168323,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    351,
                    6
                ],
                [
                    5,
                    207
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.20618370175361633,
            "test_accuracy": 0.9278752207756042,
            "test_auc": 0.9773882627487183,
            "classification_report": {
                "Benigno": {
                    "precision": 0.93646408839779,
                    "recall": 0.9495798319327731,
                    "f1-score": 0.9429763560500696,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9130434782608695,
                    "recall": 0.8915094339622641,
                    "f1-score": 0.9021479713603818,
                    "support": 212.0
                },
                "accuracy": 0.9279437609841827,
                "macro avg": {
                    "precision": 0.9247537833293298,
                    "recall": 0.9205446329475186,
                    "f1-score": 0.9225621637052257,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9277379559741923,
                    "recall": 0.9279437609841827,
                    "f1-score": 0.9277643744082175,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.93646408839779,
                    "recall": 0.9495798319327731,
                    "f1-score": 0.9429763560500696,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9130434782608695,
                    "recall": 0.8915094339622641,
                    "f1-score": 0.9021479713603818,
                    "support": 212.0
                },
                "accuracy": 0.9279437609841827,
                "macro avg": {
                    "precision": 0.9247537833293298,
                    "recall": 0.9205446329475186,
                    "f1-score": 0.9225621637052257,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9277379559741923,
                    "recall": 0.9279437609841827,
                    "f1-score": 0.9277643744082175,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    339,
                    18
                ],
                [
                    23,
                    189
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.0647599846124649,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.9967061281204224,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9832869080779945,
                    "recall": 0.988795518207283,
                    "f1-score": 0.9860335195530726,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9809523809523809,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.976303317535545,
                    "support": 212.0
                },
                "accuracy": 0.9824253075571178,
                "macro avg": {
                    "precision": 0.9821196445151876,
                    "recall": 0.9802468157074151,
                    "f1-score": 0.9811684185443088,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9824171018378712,
                    "recall": 0.9824253075571178,
                    "f1-score": 0.9824082070263312,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9832869080779945,
                    "recall": 0.988795518207283,
                    "f1-score": 0.9860335195530726,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9809523809523809,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.976303317535545,
                    "support": 212.0
                },
                "accuracy": 0.9824253075571178,
                "macro avg": {
                    "precision": 0.9821196445151876,
                    "recall": 0.9802468157074151,
                    "f1-score": 0.9811684185443088,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9824171018378712,
                    "recall": 0.9824253075571178,
                    "f1-score": 0.9824082070263312,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    353,
                    4
                ],
                [
                    6,
                    206
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.09490922093391418,
            "test_accuracy": 0.9824561476707458,
            "test_auc": 0.991911768913269,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9889196675900277,
                    "recall": 1.0,
                    "f1-score": 0.9944289693593314,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 1.0,
                    "recall": 0.9811320754716981,
                    "f1-score": 0.9904761904761905,
                    "support": 212.0
                },
                "accuracy": 0.9929701230228472,
                "macro avg": {
                    "precision": 0.9944598337950139,
                    "recall": 0.9905660377358491,
                    "f1-score": 0.992452579917761,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.993048016396555,
                    "recall": 0.9929701230228472,
                    "f1-score": 0.9929562292482138,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9889196675900277,
                    "recall": 1.0,
                    "f1-score": 0.9944289693593314,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 1.0,
                    "recall": 0.9811320754716981,
                    "f1-score": 0.9904761904761905,
                    "support": 212.0
                },
                "accuracy": 0.9929701230228472,
                "macro avg": {
                    "precision": 0.9944598337950139,
                    "recall": 0.9905660377358491,
                    "f1-score": 0.992452579917761,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.993048016396555,
                    "recall": 0.9929701230228472,
                    "f1-score": 0.9929562292482138,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    357,
                    0
                ],
                [
                    4,
                    208
                ]
            ]
        }
    },
    {
        "test_evaluation": {
            "test_loss": 0.0760665088891983,
            "test_accuracy": 0.9736841917037964,
            "test_auc": 0.9852603673934937,
            "classification_report": {
                "Benigno": {
                    "precision": 0.9833795013850416,
                    "recall": 0.9943977591036415,
                    "f1-score": 0.9888579387186629,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9903846153846154,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9809523809523809,
                    "support": 212.0
                },
                "accuracy": 0.9859402460456942,
                "macro avg": {
                    "precision": 0.9868820583848286,
                    "recall": 0.9830479361555944,
                    "f1-score": 0.9849051598355218,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9859894911353222,
                    "recall": 0.9859402460456942,
                    "f1-score": 0.9859124584964277,
                    "support": 569.0
                }
            }
        },
        "all_data_evaluation": {
            "classification_report_all": {
                "Benigno": {
                    "precision": 0.9833795013850416,
                    "recall": 0.9943977591036415,
                    "f1-score": 0.9888579387186629,
                    "support": 357.0
                },
                "Maligno": {
                    "precision": 0.9903846153846154,
                    "recall": 0.9716981132075472,
                    "f1-score": 0.9809523809523809,
                    "support": 212.0
                },
                "accuracy": 0.9859402460456942,
                "macro avg": {
                    "precision": 0.9868820583848286,
                    "recall": 0.9830479361555944,
                    "f1-score": 0.9849051598355218,
                    "support": 569.0
                },
                "weighted avg": {
                    "precision": 0.9859894911353222,
                    "recall": 0.9859402460456942,
                    "f1-score": 0.9859124584964277,
                    "support": 569.0
                }
            },
            "confusion_matrix_all": [
                [
                    355,
                    2
                ],
                [
                    6,
                    206
                ]
            ]
        }
    }
]