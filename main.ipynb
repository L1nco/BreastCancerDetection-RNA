{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports necessários para o funcionamento da RNA\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt #type: ignore\n",
    "import pandas as pd #type: ignore\n",
    "from sklearn.model_selection import train_test_split #type: ignore\n",
    "from sklearn.preprocessing import StandardScaler #type: ignore\n",
    "from sklearn.metrics import roc_curve, auc #type: ignore\n",
    "import tensorflow as tf #type: ignore\n",
    "from tensorflow.keras.models import Sequential #type: ignore\n",
    "from tensorflow.keras.layers import Dense, Dropout #type: ignore\n",
    "from tensorflow.keras.optimizers import Adam #type: ignore\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report #type: ignore\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamento dos dados e tratamento das informações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignorar mensagens desnecessárias no terminal durante o desenvolvimento em casos de erros (Como já está correto, estamos deixando ausente)\n",
    "'''os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)'''\n",
    "\n",
    "#Carregamento do arquivo do Banco de dados CSV \n",
    "file_path = os.path.join('data.csv')\n",
    "\n",
    "if file_path:\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro: {e}\")\n",
    "\n",
    "#Verificação visual caso exista algum dado ausente no Banco de Dados (Como já verificamos, estamos deixando ausente)\n",
    "'''print(\"Dados ausentes por coluna:\")\n",
    "print(data.isnull().sum())'''\n",
    "\n",
    "#Remover colunas desnecessárias\n",
    "if 'Unnamed: 32' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 32'])\n",
    "if 'id' in data.columns:\n",
    "    ids = data['id']  \n",
    "    data = data.drop(columns=['id'])\n",
    "\n",
    "#Convertendo o diagnosis para valores 0 e 1, indicando Maligno e Benigno\n",
    "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
    "\n",
    "#Tratamento\n",
    "if data.isnull().sum().sum() > 0:\n",
    "    data = data.dropna()\n",
    "\n",
    "#Divisão dos dados em características X e Y\n",
    "X = data.drop(columns=['diagnosis'])\n",
    "y = data['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solicitando ao usuário escolher o conjunto de treinamento da rede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solicitar ao usuário o tamanho do conjunto de treinamento para a rede neural (Finalidade de realizar 10 testes para verificarmos sua melhoria)\n",
    "while True:\n",
    "    try:\n",
    "        test_size = float(input(\"Escolha o conjunto para treinamento (Valores entre 0 e 1): \"))\n",
    "        if 0 < test_size < 1:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Insira um valor entre 0 e 1. (Exemplo 0.8)\")\n",
    "    except ValueError:\n",
    "        print(\"Valor inválido.\")\n",
    "\n",
    "test_size = 1 - test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo os dados para treinamento da rede\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "#Normalização dos dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_scaled = scaler.transform(X)   \n",
    "\n",
    "#Modelo utilizando Relu e saída Sigmoid, pois foram os melhores resultados encontrados. \n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "#Compilando o modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy', 'AUC'])\n",
    "\n",
    "#Treinamento do modelo com 500 épocas para treino (Acreditamos ser o suficiente neste contexto)\n",
    "history = model.fit(X_train, y_train, epochs=500, validation_split=0.2, batch_size=32, verbose=1, callbacks=[])\n",
    "\n",
    "#Rodar o modelo treinado em cima de todos os dados (sem divisão de treino/teste)\n",
    "y_pred_all = (model.predict(X_scaled) > 0.5).astype(\"int32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação do modelo utilizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Avaliando o modelo\n",
    "test_loss, test_accuracy, test_auc = model.evaluate(X_test, y_test, verbose=0)\n",
    "y_pred_prob = model.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(f'Acurácia: {test_accuracy:.4f}')\n",
    "print(f'AUC: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico da acurácia e perda do treinamento gerados após a execução do código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico da acurácia\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Acurácia do treinamento')\n",
    "plt.plot(history.history['val_accuracy'], label='Acurácia na Validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.title('Acurácia do treinamento')\n",
    "\n",
    "#Gráfico da Perda no treinamento\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Perda no Treinamento')\n",
    "plt.plot(history.history['val_loss'], label='Perda na Validação')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.title('Perda no Treinamento e na Validação')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico da validação do modelo, curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico da Curva ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'Curva ROC (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Linha de referência\n",
    "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico da Matriz de confusão gerado depois da execução do código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico da Matriz de confusão\n",
    "cm_all = confusion_matrix(y, y_pred_all)\n",
    "disp_all = ConfusionMatrixDisplay(confusion_matrix=cm_all, display_labels=['Benigno', 'Maligno'])\n",
    "disp_all.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cálculos feitos manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contas para verificação e validação manual dos resultados (Somente para fins de testes)\n",
    "verdadeiro_negativo, falso_positivo, falso_negativo, verdadeiro_positivo = cm_all.ravel()\n",
    "\n",
    "#Contas para precisão Benigno, recall e f1\n",
    "precision_benigno = verdadeiro_negativo / (verdadeiro_negativo + falso_negativo) if (verdadeiro_negativo + falso_negativo) > 0 else 0\n",
    "recall_benigno = verdadeiro_negativo / (verdadeiro_negativo + falso_positivo) if (verdadeiro_negativo + falso_positivo) > 0 else 0\n",
    "f1_benigno = 2 * (precision_benigno * recall_benigno) / (precision_benigno + recall_benigno) if (precision_benigno + recall_benigno) > 0 else 0\n",
    "\n",
    "#Contas para precisão Maligno, recall e f1\n",
    "precision_maligno = verdadeiro_positivo / (verdadeiro_positivo + falso_positivo) if (verdadeiro_positivo + falso_positivo) > 0 else 0\n",
    "recall_maligno = verdadeiro_positivo / (verdadeiro_positivo + falso_negativo) if (verdadeiro_positivo + falso_negativo) > 0 else 0\n",
    "f1_maligno = 2 * (precision_maligno * recall_maligno) / (precision_maligno + recall_maligno) if (precision_maligno + recall_maligno) > 0 else 0\n",
    "\n",
    "#Visualiação visual das métricas encontradas \n",
    "print(\"|Métricas manuais calculadas com base na Matriz de Confusão|\")\n",
    "print(f\"|Benigno | Precisão: {precision_benigno:.10f} | Recall: {recall_benigno:.10f} | F1-Score: {f1_benigno:.10f}|\")\n",
    "print(f\"|Maligno | Precisão: {precision_maligno:.10f} | Recall: {recall_maligno:.10f} | F1-Score: {f1_maligno:.10f}|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geração do relatório, salvamento de informações e caminho especificado JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Relatório de classificação\n",
    "classification_report_all = classification_report(y, y_pred_all, target_names=['Benigno', 'Maligno'], output_dict=True)\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y, y_pred_all, target_names=['Benigno', 'Maligno']))\n",
    "\n",
    "#Informações para o JSON\n",
    "results = {\n",
    "    \"test_evaluation\": {\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"test_auc\": test_auc,\n",
    "        \"classification_report\": classification_report_all \n",
    "    },\n",
    "    \"all_data_evaluation\": {\n",
    "        \"classification_report_all\": classification_report_all,\n",
    "        \"confusion_matrix_all\": cm_all.tolist()  \n",
    "    }\n",
    "}\n",
    "\n",
    "#Caminho arquivo JSON\n",
    "results_file_path = 'resultados.json'\n",
    "\n",
    "#Carregar os resultados existentes e adicionar novos resultados encontrados no arquivo JSON (Informações para o artigo)\n",
    "if os.path.exists(results_file_path):\n",
    "    with open(results_file_path, 'r') as json_file:\n",
    "        existing_results = json.load(json_file)\n",
    "else:\n",
    "    existing_results = []\n",
    "\n",
    "#Adicionar os novos resultados da execução\n",
    "existing_results.append(results)\n",
    "\n",
    "#Salvar os resultados atualizados no JSON\n",
    "with open(results_file_path, 'w') as json_file:\n",
    "    json.dump(existing_results, json_file, indent=4)\n",
    "\n",
    "#Indicando o local de salvamento dos resultados.\n",
    "print(f\"Resultados salvos em: {results_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
